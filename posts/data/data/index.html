<!DOCTYPE html>
<html lang="en-us">
<title>K. The Dataset | SOCIAL GRAPHS BLOG</title>
<meta charset="utf-8">
<meta name="generator" content="Hugo 0.89.4" />
<meta name="description" content="This is gossip girl">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="stylesheet" href="https://elisealm.github.io/socialgraphsblog.github.io/css/index.css">
<link rel="canonical" href="https://elisealm.github.io/socialgraphsblog.github.io/posts/data/data/">
<link rel="alternate" type="application/rss+xml" href="" title="SOCIAL GRAPHS BLOG">

<header>
  
    <a href="https://elisealm.github.io/socialgraphsblog.github.io/" class="title">SOCIAL GRAPHS BLOG</a>
  
  
</header>

<article>
  <header>
    <h1>K. The Dataset</h1>
    
  </header>
  <div style="flex:auto;">
    <h3 style="font-family: Impact, Haettenschweiler, 'Arial Narrow Bold', sans-serif;"> Data and basic stats</h3>
    
    </div>
<p>Data cleaning and preprocessing has ben used to fetch:
<ul>
    <li>List of charachters</li>
    <li>The chrachters relatioships </li>
    <li>The gender of the charachters </li>
    <li>The Description of the charachter </li>
</ul></p>
<p>The data has been fetched to be used for Network analasys and text analasys.</p>
<div style="flex:auto;">
    <h3 style="font-family: Impact, Haettenschweiler, 'Arial Narrow Bold', sans-serif;"> Data Cleaning and preprosseding</h3>
    
    </div>
<p>To prosses and clean data the very popular Pytonlibrary Beautiful Soup has been used. Al data has been fetched by using the html tag and a unique identifier. The soup has then been cleaned by removing dublicates and data that we don&rsquo;t want to use like in the list of charachter one charachter is: &lsquo;Breakfast&rsquo;.  For the description the text has been cleaned by using regular expression operations. The text was cleaned to be a list of words for worcloud and a list of setences for sentiment analasys.</p>
<p>Our data is not very large, and we encountered some issues while prossesig the data. We had to add a main charachter. The page for eachcharachter contains a set of paragraphs that are enncapsulated in the same main with noidentifier. This constricted us a bit.</p>
<p>The dataset that we will be analyzing consists of the wikipages:
<ul>
    <li>Characters</li>
    <li>Episodes</li>
    <li>Seasons</li>
    <li>Categories</li>
</ul>
This became approximatley 248 wiki pages.</p>
<p><img src="https://elisealm.github.io/socialgraphsblog.github.io/





/images/dataset.jpg" alt="Graph"></p>

</article>



</html>
